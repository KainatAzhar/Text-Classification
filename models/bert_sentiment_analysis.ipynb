{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning BERT for Sentiment Analysis\n",
    "\n",
    "This notebook demonstrates how to fine-tune a pre-trained BERT model for a text classification task using the IMDb movie review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Dataset\n",
    "\n",
    "We use the `datasets` library from Hugging Face to easily load the IMDb dataset. We'll then create a smaller subset for faster training as a demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDb dataset\n",
    "dataset = load_dataset('imdb')\n",
    "\n",
    "# For demonstration purposes, let's use a smaller subset of the data\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select(range(2000)) # 2000 examples for training\n",
    "test_dataset = dataset['test'].shuffle(seed=42).select(range(500))   # 500 examples for testing\n",
    "\n",
    "print(\"Training data sample:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization\n",
    "\n",
    "We need to tokenize the text data into a format that BERT can understand. We'll use the tokenizer corresponding to the 'bert-base-uncased' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create a tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "# Apply the tokenization to our datasets\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Fine-Tuning\n",
    "\n",
    "Now we load the pre-trained BERT model and set up the `Trainer` API to fine-tune it on our specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define a function to compute metrics for evaluation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Create the Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "Let's evaluate the final performance of our fine-tuned model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final evaluation on the test set:\")\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Model and Tokenizer\n",
    "\n",
    "We'll save our fine-tuned model so we can use it for inference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = \"../models/fine-tuned-bert\"\n",
    "trainer.save_model(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inference on New Text\n",
    "\n",
    "Finally, let's use our saved model to predict the sentiment of a new movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the fine-tuned model using a pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=model_save_path, tokenizer=model_save_path)\n",
    "\n",
    "# Test with a positive review\n",
    "positive_review = \"This movie was absolutely fantastic! The acting was superb and the plot was gripping.\"\n",
    "result_pos = sentiment_analyzer(positive_review)\n",
    "print(f\"Review: '{positive_review}'\")\n",
    "print(f\"Prediction: {result_pos}\")\n",
    "\n",
    "# Test with a negative review\n",
    "negative_review = \"I was really disappointed with this film. It was boring and the ending was predictable.\"\n",
    "result_neg = sentiment_analyzer(negative_review)\n",
    "print(f\"\\nReview: '{negative_review}'\")\n",
    "print(f\"Prediction: {result_neg}\")"
   ]
  }
 ]
}
